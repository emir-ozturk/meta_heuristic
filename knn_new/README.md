# GeliÅŸtirilmiÅŸ KNN Meta-sezgisel Hiperparametre Optimizasyonu

Bu klasÃ¶r, KNN hiperparametre optimizasyonu iÃ§in geliÅŸtirilmiÅŸ meta-sezgisel algoritma implementasyonunu iÃ§erir.

## ğŸš¨ Ana Problem ve Ã‡Ã¶zÃ¼mÃ¼

### Problem:
Mevcut implementasyonda **"K=15 ve K=67 aynÄ± accuracy veriyorsa neden K=67 Ã¶neriliyor?"** sorunu vardÄ±. Bu problem ÅŸu nedenlerden kaynaklanÄ±yordu:
- Sadece accuracy maksimize ediliyordu
- Computational cost gÃ¶z Ã¶nÃ¼nde bulundurulmuyordu
- Cross-validation kullanÄ±lmÄ±yordu (overfitting riski)
- Model simplicity optimize edilmiyordu

### Ã‡Ã¶zÃ¼m:
âœ… **Multi-objective optimization**: Accuracy + Model Simplicity  
âœ… **Cross-validation**: Daha gÃ¼venilir performans deÄŸerlendirmesi  
âœ… **Complexity penalty**: DÃ¼ÅŸÃ¼k K deÄŸerleri tercih ediliyor  
âœ… **Smart K recommendation**: AynÄ± accuracy'deki en dÃ¼ÅŸÃ¼k K Ã¶neriliyor  

## ğŸ¯ Yeni Ã–zellikler

### 1. Cross-Validation DesteÄŸi
```python
problem = KnnMetaHeuristicProblem(
    attributes, target,
    use_cv=True,           # Cross-validation kullan
    cv_folds=5,           # 5-fold CV
    complexity_weight=0.1  # Complexity penalty aÄŸÄ±rlÄ±ÄŸÄ±
)
```

### 2. Multi-objective Optimization
- **Accuracy**: Ana performans metriÄŸi
- **Complexity Penalty**: K deÄŸeri bÃ¼yÃ¼dÃ¼kÃ§e penalty artar
- **Final Score** = Accuracy - (complexity_weight Ã— complexity_penalty)

### 3. AkÄ±llÄ± K Ã–nerisi
```python
recommendation = problem.recommend_optimal_k()
print(f"Ã–nerilen K: {recommendation['recommended_k']}")
print(f"Accuracy: {recommendation['accuracy']}")
print(f"AÃ§Ä±klama: {recommendation['reasoning']}")
```

### 4. Pareto Front Analizi
Accuracy vs Complexity trade-off'unu gÃ¶rselleÅŸtirin:
```python
from utils.visualize_new import plot_pareto_analysis
plot_pareto_analysis(problem)
```

## ğŸ“ Dosya YapÄ±sÄ±

```
knn_new/
â”œâ”€â”€ knn_problem.py           # GeliÅŸtirilmiÅŸ KNN problem sÄ±nÄ±fÄ±
â”œâ”€â”€ knn_problem_bounds.py    # Esnek bound konfigÃ¼rasyonlarÄ±
â””â”€â”€ README.md               # Bu dosya

utils/
â””â”€â”€ visualize_new.py        # GeliÅŸmiÅŸ gÃ¶rselleÅŸtirme araÃ§larÄ±

knn_new_example.ipynb       # DetaylÄ± Ã¶rnek notebook
```

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Basit KullanÄ±m
```python
from knn_new.knn_problem import KnnMetaHeuristicProblem
from knn_new.knn_problem_bounds import get_recommended_config
from mealpy import PSO

# Dataset yÃ¼kle
df = pd.read_csv("datasets/diabetes.csv")
X = df.drop("Outcome", axis=1)
y = df["Outcome"]

# Otomatik konfigÃ¼rasyon
config = get_recommended_config(len(df))

# Problem oluÅŸtur
problem = KnnMetaHeuristicProblem(
    X, y, 
    bounds=config['bounds'],
    complexity_weight=config['complexity_weight']
)

# Optimize et
model = PSO.OriginalPSO(epoch=50)
model.solve(problem)

# Optimal K Ã¶nerisi al
recommendation = problem.recommend_optimal_k()
print(f"Ã–nerilen K: {recommendation['recommended_k']}")
```

### GeliÅŸmiÅŸ KullanÄ±m
```python
# FarklÄ± optimizasyon stratejileri
strategies = ['accuracy_focused', 'balanced', 'efficiency_focused']

for strategy in strategies:
    problem = KnnMetaHeuristicProblem(
        X, y,
        bounds=get_bounds_for_strategy('cv'),
        complexity_weight=COMPLEXITY_CONFIGS[strategy]['complexity_weight']
    )
    # ... optimize et
```

## ğŸ“Š KonfigÃ¼rasyon SeÃ§enekleri

### 1. Dataset Boyutuna GÃ¶re Otomatik Ayar
```python
config = get_recommended_config(dataset_size)
# < 1000 samples: Quick mode
# 1000-10000: Balanced mode  
# > 10000: Efficiency mode
```

### 2. Complexity Weight Stratejileri
- **accuracy_focused** (0.01): Sadece accuracy odaklÄ±
- **balanced** (0.1): Dengeli optimizasyon
- **efficiency_focused** (0.2): DÃ¼ÅŸÃ¼k K deÄŸerleri tercih

### 3. Bounds Stratejileri
- **cv**: Cross-validation iÃ§in (test_size gereksiz)
- **split**: Train/test split iÃ§in
- **quick**: HÄ±zlÄ± test iÃ§in dar aralÄ±k

## ğŸ”¬ CV'ye KatkÄ±larÄ±

### Teknik Yeterlikler
1. **Multi-objective Optimization**: Birden fazla hedefi aynÄ± anda optimize etme
2. **Cross-validation Expertise**: Overfitting Ã¶nleme ve gÃ¼venilir performans
3. **Meta-heuristic Algorithms**: PSO, GA, ABC, SOS algoritmalarÄ±nda uzmanlik
4. **Hyperparameter Tuning**: Production-ready hiperparametre optimizasyonu

### Pratik Faydalar
1. **Daha az computational cost**: DÃ¼ÅŸÃ¼k K deÄŸerleri tercih
2. **Daha gÃ¼venilir sonuÃ§lar**: CV ile overfitting azalmasÄ±
3. **Scalable solution**: Dataset boyutuna gÃ¶re adaptive konfigÃ¼rasyon
4. **Interpretable results**: Pareto analizi ile trade-off gÃ¶rÃ¼nÃ¼rlÃ¼ÄŸÃ¼

## ğŸ†š Eski vs Yeni KarÅŸÄ±laÅŸtÄ±rma

| Ã–zellik | Eski Implementation | Yeni Implementation |
|---------|-------------------|-------------------|
| Evaluation | Single train/test split | Cross-validation |
| Objective | Sadece accuracy | Multi-objective (accuracy + simplicity) |
| K Selection | Rastgele yÃ¼ksek K | AkÄ±llÄ± dÃ¼ÅŸÃ¼k K Ã¶nerisi |
| Overfitting | Risk var | CV ile azaltÄ±lmÄ±ÅŸ |
| Computational Cost | GÃ¶z ardÄ± ediliyor | Optimize ediliyor |
| Analysis | Basit | Pareto front + efficiency analysis |

## ğŸ“ˆ Ã–rnek SonuÃ§lar

**Eski Sistem:**
- K=67, Accuracy=0.804
- Neden yÃ¼ksek K? â†’ Belirsiz

**Yeni Sistem:**
- K=15, Accuracy=0.803, Final Score=0.791
- Reasoning: "K=15 gives 0.803 accuracy with lower computational cost"
- Alternative K values: [15, 17, 19, 23]

## ğŸ”§ Troubleshooting

### YaygÄ±n Problemler
1. **YavaÅŸ Ã§alÄ±ÅŸma**: `strategy='quick'` kullanÄ±n
2. **Memory issues**: `cv_folds` azaltÄ±n
3. **Poor convergence**: `complexity_weight` azaltÄ±n

### Performance Tuning
```python
# HÄ±zlÄ± test iÃ§in
bounds = get_bounds_for_strategy('quick')
termination = get_termination_for_strategy('quick')

# BÃ¼yÃ¼k dataset iÃ§in
config = get_recommended_config(dataset_size)
# Otomatik olarak efficiency_focused olacak
```

## ğŸ“š Daha Fazla Bilgi

- `knn_new_example.ipynb`: DetaylÄ± Ã¶rnek ve karÅŸÄ±laÅŸtÄ±rmalar
- `utils/visualize_new.py`: GÃ¶rselleÅŸtirme fonksiyonlarÄ±
- Mealpy Documentation: [https://mealpy.readthedocs.io/](https://mealpy.readthedocs.io/)

---

**ğŸ¯ SonuÃ§**: Bu geliÅŸtirilmiÅŸ implementasyon ile artÄ±k K=67 yerine K=15 gibi daha efficiency odaklÄ± ve mantÄ±klÄ± Ã¶neriler alacaksÄ±nÄ±z! 